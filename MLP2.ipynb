{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6597e432-afa7-4ae8-ae43-0c0f25cabc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "685f6188-4d92-41b2-afa3-f7fd8f962528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, features_file, label_file):\n",
    "        self.features = pd.read_csv(features_file)\n",
    "        self.labels = pd.read_csv(label_file)\n",
    "\n",
    "        # Compute mean and standard deviation for Z-score normalization\n",
    "        self.features_mean = self.features.mean()\n",
    "        self.features_std = self.features.std()\n",
    "        \n",
    "        self.labels_mean = self.labels.mean()\n",
    "        self.labels_std = self.labels.std()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Select the row\n",
    "        feature_row = self.features.iloc[idx].values\n",
    "        label_row = self.labels.iloc[idx].values\n",
    "\n",
    "        # Normalize features and labels using Z-score\n",
    "        normalized_features = (feature_row - self.features_mean) / self.features_std\n",
    "        normalized_labels = (label_row - self.labels_mean) / self.labels_std\n",
    "\n",
    "        # Convert to tensors\n",
    "        tensor_features = torch.tensor(normalized_features, dtype=torch.float)\n",
    "        tensor_labels = torch.tensor(normalized_labels, dtype=torch.float)\n",
    "\n",
    "        return tensor_features, tensor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bba93302-b8ce-4113-ac29-7bdfa5d3c881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60761"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f37718a-e3f0-4b0a-a9d8-8732bb7025bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      " tensor([[-0.4869, -0.3777, -0.6607, -0.6532, -0.6401, -0.4930, -0.6558, -0.5030],\n",
      "        [-0.3777, -0.6607, -0.6532, -0.6400, -0.4930, -0.6558, -0.5030, -0.3775],\n",
      "        [-0.6607, -0.6532, -0.6400, -0.4930, -0.6558, -0.5030, -0.3775, -0.4131],\n",
      "        [-0.6532, -0.6400, -0.4929, -0.6558, -0.5030, -0.3775, -0.4131, -0.5820],\n",
      "        [-0.6400, -0.4929, -0.6558, -0.5030, -0.3774, -0.4131, -0.5820, -0.6609],\n",
      "        [-0.4929, -0.6558, -0.5030, -0.3774, -0.4130, -0.5821, -0.6609, -0.5164],\n",
      "        [-0.6558, -0.5029, -0.3774, -0.4130, -0.5820, -0.6610, -0.5163, -0.6170],\n",
      "        [-0.5029, -0.3774, -0.4130, -0.5820, -0.6610, -0.5164, -0.6169, -0.6220],\n",
      "        [-0.3774, -0.4130, -0.5820, -0.6610, -0.5163, -0.6170, -0.6220, -0.3877],\n",
      "        [-0.4130, -0.5820, -0.6609, -0.5163, -0.6170, -0.6220, -0.3877, -0.5111],\n",
      "        [-0.5820, -0.6609, -0.5163, -0.6170, -0.6220, -0.3877, -0.5111, -0.6613],\n",
      "        [-0.6609, -0.5163, -0.6169, -0.6220, -0.3877, -0.5111, -0.6613, -0.6658],\n",
      "        [-0.5163, -0.6169, -0.6220, -0.3877, -0.5111, -0.6614, -0.6658, -0.6185],\n",
      "        [-0.6169, -0.6220, -0.3876, -0.5111, -0.6614, -0.6659, -0.6185, -0.5156],\n",
      "        [-0.6220, -0.3876, -0.5111, -0.6613, -0.6659, -0.6185, -0.5156, -0.6606],\n",
      "        [-0.3876, -0.5111, -0.6613, -0.6658, -0.6185, -0.5156, -0.6606, -0.3433],\n",
      "        [-0.5111, -0.6613, -0.6658, -0.6185, -0.5156, -0.6606, -0.3433, -0.1995],\n",
      "        [-0.6613, -0.6658, -0.6185, -0.5156, -0.6606, -0.3433, -0.1995, -0.5299],\n",
      "        [-0.6658, -0.6185, -0.5156, -0.6606, -0.3432, -0.1995, -0.5299, -0.6566],\n",
      "        [-0.6185, -0.5155, -0.6606, -0.3432, -0.1994, -0.5300, -0.6565, -0.6621],\n",
      "        [-0.5155, -0.6606, -0.3432, -0.1994, -0.5299, -0.6566, -0.6621,  0.6179],\n",
      "        [-0.6606, -0.3432, -0.1994, -0.5299, -0.6566, -0.6622,  0.6180,  2.0761],\n",
      "        [-0.3432, -0.1994, -0.5299, -0.6566, -0.6622,  0.6182,  2.0761,  0.5355],\n",
      "        [-0.1994, -0.5299, -0.6566, -0.6621,  0.6183,  2.0768,  0.5356,  0.4548],\n",
      "        [-0.5299, -0.6566, -0.6621,  0.6183,  2.0769,  0.5358,  0.4549,  0.0578],\n",
      "        [-0.6565, -0.6621,  0.6183,  2.0769,  0.5359,  0.4551,  0.0578, -0.0668],\n",
      "        [-0.6621,  0.6183,  2.0769,  0.5359,  0.4552,  0.0580, -0.0668,  0.0824],\n",
      "        [ 0.6183,  2.0769,  0.5359,  0.4552,  0.0580, -0.0667,  0.0824,  0.1354],\n",
      "        [ 2.0769,  0.5359,  0.4552,  0.0580, -0.0666,  0.0826,  0.1354,  0.2955],\n",
      "        [ 0.5359,  0.4552,  0.0580, -0.0666,  0.0826,  0.1355,  0.2955,  0.0797],\n",
      "        [ 0.4552,  0.0580, -0.0666,  0.0826,  0.1356,  0.2957,  0.0797,  0.2675],\n",
      "        [ 0.0580, -0.0666,  0.0826,  0.1356,  0.2958,  0.0799,  0.2676, -0.0819],\n",
      "        [-0.0666,  0.0826,  0.1356,  0.2958,  0.0799,  0.2677, -0.0819,  1.0036],\n",
      "        [ 0.0826,  0.1356,  0.2958,  0.0799,  0.2678, -0.0818,  1.0037, -0.4749],\n",
      "        [ 0.1356,  0.2958,  0.0799,  0.2678, -0.0818,  1.0040, -0.4749, -0.1701],\n",
      "        [ 0.2958,  0.0800,  0.2678, -0.0818,  1.0041, -0.4749, -0.1701, -0.2465],\n",
      "        [ 0.0800,  0.2678, -0.0818,  1.0041, -0.4749, -0.1700, -0.2464, -0.2161],\n",
      "        [ 0.2678, -0.0817,  1.0041, -0.4749, -0.1700, -0.2464, -0.2161, -0.3845],\n",
      "        [-0.0817,  1.0041, -0.4749, -0.1700, -0.2464, -0.2160, -0.3845, -0.4400],\n",
      "        [ 1.0041, -0.4749, -0.1700, -0.2464, -0.2160, -0.3845, -0.4399, -0.2512],\n",
      "        [-0.4749, -0.1700, -0.2463, -0.2160, -0.3845, -0.4399, -0.2512, -0.1632],\n",
      "        [-0.1700, -0.2463, -0.2160, -0.3844, -0.4399, -0.2512, -0.1632, -0.3597],\n",
      "        [-0.2463, -0.2159, -0.3844, -0.4399, -0.2511, -0.1631, -0.3596, -0.4465],\n",
      "        [-0.2159, -0.3844, -0.4399, -0.2511, -0.1631, -0.3596, -0.4465, -0.2802],\n",
      "        [-0.3844, -0.4399, -0.2511, -0.1631, -0.3596, -0.4465, -0.2801, -0.4141],\n",
      "        [-0.4399, -0.2511, -0.1631, -0.3596, -0.4465, -0.2801, -0.4141, -0.4562],\n",
      "        [-0.2511, -0.1630, -0.3596, -0.4465, -0.2801, -0.4141, -0.4562, -0.1975],\n",
      "        [-0.1630, -0.3596, -0.4465, -0.2801, -0.4141, -0.4562, -0.1975,  0.0312],\n",
      "        [-0.3595, -0.4465, -0.2801, -0.4141, -0.4562, -0.1975,  0.0312, -0.4335],\n",
      "        [-0.4465, -0.2801, -0.4141, -0.4562, -0.1974,  0.0313, -0.4335, -0.6000],\n",
      "        [-0.2800, -0.4140, -0.4562, -0.1974,  0.0313, -0.4335, -0.6000, -0.5604],\n",
      "        [-0.4140, -0.4561, -0.1974,  0.0314, -0.4335, -0.6000, -0.5604, -0.3975],\n",
      "        [-0.4561, -0.1974,  0.0314, -0.4335, -0.6000, -0.5604, -0.3975, -0.4345],\n",
      "        [-0.1974,  0.0314, -0.4335, -0.6000, -0.5604, -0.3975, -0.4344, -0.2782],\n",
      "        [ 0.0314, -0.4335, -0.6000, -0.5604, -0.3974, -0.4344, -0.2782, -0.5533],\n",
      "        [-0.4335, -0.6000, -0.5604, -0.3974, -0.4344, -0.2781, -0.5533,  0.8119],\n",
      "        [-0.6000, -0.5603, -0.3974, -0.4344, -0.2781, -0.5533,  0.8120, -0.2448],\n",
      "        [-0.5603, -0.3974, -0.4344, -0.2781, -0.5533,  0.8123, -0.2448, -0.3473],\n",
      "        [-0.3974, -0.4344, -0.2781, -0.5533,  0.8124, -0.2447, -0.3473,  0.4421],\n",
      "        [-0.4344, -0.2781, -0.5533,  0.8124, -0.2447, -0.3472,  0.4421,  0.7701],\n",
      "        [-0.2780, -0.5533,  0.8124, -0.2447, -0.3472,  0.4423,  0.7702,  1.3211],\n",
      "        [-0.5532,  0.8124, -0.2447, -0.3472,  0.4424,  0.7705,  1.3212,  0.1797],\n",
      "        [ 0.8124, -0.2447, -0.3472,  0.4424,  0.7705,  1.3216,  0.1797,  1.4045],\n",
      "        [-0.2446, -0.3472,  0.4424,  0.7705,  1.3217,  0.1798,  1.4045,  6.0261]])\n",
      "Labels:\n",
      " tensor([[-1.0539e-01,  1.0473e-01, -3.5338e-02, -1.6760e-01, -2.7249e-02,\n",
      "         -6.3469e-01],\n",
      "        [-1.0543e-01, -7.1079e-01, -3.5330e-02,  9.9417e-03, -1.7836e-02,\n",
      "         -6.0646e-01],\n",
      "        [-1.0541e-01,  1.0473e-01, -3.5334e-02, -3.2422e-01, -2.6757e-02,\n",
      "          2.0452e+00],\n",
      "        [-1.0539e-01,  1.0473e-01, -3.5332e-02, -3.8593e-01, -3.1679e-02,\n",
      "          2.2999e-01],\n",
      "        [-1.0546e-01, -7.1080e-01, -3.5335e-02, -3.8584e-01, -2.5896e-02,\n",
      "         -5.6921e-01],\n",
      "        [-1.0540e-01,  1.0473e-01, -3.5335e-02, -1.6002e-01, -2.1189e-02,\n",
      "         -5.4267e-01],\n",
      "        [-1.0545e-01,  1.0473e-01, -3.5328e-02, -3.2267e-01, -2.6511e-02,\n",
      "         -5.5340e-01],\n",
      "        [-1.0540e-01, -7.1079e-01, -3.5333e-02, -3.3350e-01, -3.2663e-02,\n",
      "         -5.7711e-01],\n",
      "        [-1.0540e-01,  1.0473e-01, -3.5334e-02,  9.6850e-03, -2.9894e-02,\n",
      "         -5.4324e-01],\n",
      "        [-1.0544e-01,  1.0473e-01, -3.5330e-02, -1.6606e-01, -2.4327e-02,\n",
      "         -5.5058e-01],\n",
      "        [-1.0544e-01, -7.1079e-01, -3.5336e-02, -3.8583e-01,  6.6766e-01,\n",
      "         -6.8098e-01],\n",
      "        [-1.0541e-01, -7.1079e-01, -3.5329e-02, -3.8585e-01,  3.5855e-01,\n",
      "         -5.7372e-01],\n",
      "        [-1.0544e-01,  1.0473e-01, -3.5337e-02, -3.3115e-01,  3.6615e-01,\n",
      "         -7.2896e-01],\n",
      "        [-1.0549e-01, -7.1080e-01, -3.5332e-02, -1.6985e-01, -1.8236e-02,\n",
      "         -7.2219e-01],\n",
      "        [-1.0552e-01, -1.5263e+00, -3.5334e-02, -3.8583e-01, -2.2266e-02,\n",
      "         -7.0243e-01],\n",
      "        [-1.0548e-01,  1.0472e-01, -3.5325e-02, -2.2559e-01, -3.6293e-02,\n",
      "          2.0147e+00],\n",
      "        [-1.0529e-01,  1.0474e-01, -3.5333e-02,  4.0982e-03, -3.0448e-02,\n",
      "          1.9512e+00],\n",
      "        [-1.0550e-01, -7.1080e-01, -3.5332e-02, -2.5177e-01, -1.9805e-02,\n",
      "          1.0128e-01],\n",
      "        [-1.0529e-01,  1.0474e-01, -3.5333e-02, -3.8578e-01, -2.0543e-02,\n",
      "         -5.4437e-01],\n",
      "        [-1.0546e-01, -7.1080e-01, -3.5331e-02, -3.8593e-01, -1.5745e-02,\n",
      "         -6.2679e-01],\n",
      "        [-9.4886e-02,  9.2100e-01,  1.8059e-01, -2.9678e-01, -4.1952e-02,\n",
      "         -6.2058e-01],\n",
      "        [-1.0549e-01, -7.1080e-01,  3.7278e-01, -2.0276e-01, -1.9436e-02,\n",
      "          2.2581e+00],\n",
      "        [ 4.0902e-01,  1.4122e-01,  2.8217e-02, -1.3644e-01, -2.9987e-02,\n",
      "          1.6221e+00],\n",
      "        [ 6.3640e-01,  9.7287e-01, -3.5333e-02, -4.9213e-04, -3.2263e-02,\n",
      "          1.7246e+00],\n",
      "        [ 2.4313e-01,  9.4497e-01, -3.5326e-02, -3.8591e-01, -4.2568e-02,\n",
      "          1.7114e+00],\n",
      "        [-1.0546e-01, -7.1080e-01, -3.5332e-02, -3.8585e-01, -2.6972e-02,\n",
      "          1.9005e+00],\n",
      "        [-1.0545e-01,  1.0473e-01, -3.5333e-02, -1.8923e-01, -5.2688e-02,\n",
      "          2.3953e+00],\n",
      "        [-1.0536e-01,  1.0473e-01, -3.5332e-02, -7.2054e-02, -5.2257e-02,\n",
      "          2.1381e+00],\n",
      "        [-1.0535e-01,  1.0473e-01, -3.5319e-02,  1.7758e-01, -5.2011e-02,\n",
      "          1.5235e+00],\n",
      "        [-1.0543e-01,  1.0473e-01, -3.5332e-02, -1.7146e-01, -4.4967e-02,\n",
      "          1.9962e+00],\n",
      "        [-1.0546e-01,  1.0473e-01, -3.5336e-02,  5.7692e-03, -5.4872e-02,\n",
      "          2.9197e+00],\n",
      "        [-1.0548e-01,  1.0472e-01, -3.5330e-02,  2.1438e-02, -5.4472e-02,\n",
      "          2.6789e+00],\n",
      "        [-1.0548e-01, -7.1080e-01,  1.8678e-01, -1.5929e-01, -5.3365e-02,\n",
      "          1.5449e+00],\n",
      "        [-6.9446e-02,  1.0728e-01, -3.5323e-02, -3.8079e-01, -4.6197e-02,\n",
      "          1.5533e+00],\n",
      "        [ 1.6407e-02,  9.2889e-01, -3.5333e-02, -1.5152e-01, -5.5179e-02,\n",
      "          1.2806e+00],\n",
      "        [ 3.3965e-02,  9.3014e-01, -3.5334e-02,  1.8634e-02, -5.7917e-02,\n",
      "         -6.2453e-01],\n",
      "        [ 3.6057e-02,  1.1476e-01, -3.5333e-02,  6.9988e-02, -5.7486e-02,\n",
      "         -6.2114e-01],\n",
      "        [ 3.6015e-02,  1.1476e-01, -3.5330e-02, -2.1063e-01, -4.8412e-02,\n",
      "         -4.4102e-01],\n",
      "        [-1.7409e-02,  1.7420e+00, -3.5334e-02, -3.5990e-01, -5.6840e-02,\n",
      "          1.1086e+00],\n",
      "        [-3.2779e-02,  9.2540e-01, -3.5328e-02, -1.1663e-01, -5.7671e-02,\n",
      "          1.5354e+00],\n",
      "        [-3.3887e-02,  9.2532e-01, -3.5333e-02,  2.1110e-02, -5.2688e-02,\n",
      "          1.4983e+00],\n",
      "        [-3.3801e-02,  9.2533e-01, -3.5320e-02, -2.8228e-01, -3.7215e-02,\n",
      "          1.5577e+00],\n",
      "        [-3.3938e-02,  1.0980e-01, -3.5317e-02, -3.8582e-01, -5.1027e-02,\n",
      "          1.4931e+00],\n",
      "        [-4.1906e-02,  9.2475e-01, -3.5331e-02, -1.6029e-01, -5.9824e-02,\n",
      "          1.2689e+00],\n",
      "        [-5.3782e-02,  1.0839e-01, -3.5320e-02, -3.2866e-01, -5.5702e-02,\n",
      "          1.3596e+00],\n",
      "        [-5.3712e-02, -7.0712e-01, -3.5333e-02, -3.8594e-01, -4.3767e-02,\n",
      "          1.4330e+00],\n",
      "        [-5.3597e-02, -7.0712e-01, -3.5335e-02, -3.4824e-02, -5.2626e-02,\n",
      "          1.5006e+00],\n",
      "        [-5.3217e-02,  1.0843e-01,  1.9296e-02,  3.4640e-03, -5.6379e-02,\n",
      "          8.8213e-01],\n",
      "        [-5.3722e-02,  1.0840e-01, -1.4409e-02, -3.8403e-01, -5.5641e-02,\n",
      "         -1.5815e-01],\n",
      "        [-5.3501e-02,  1.0841e-01, -3.5332e-02, -3.8585e-01, -4.4167e-02,\n",
      "         -5.9179e-01],\n",
      "        [-5.3677e-02,  1.0840e-01, -3.5324e-02, -3.8581e-01, -4.9827e-02,\n",
      "         -1.9358e-01],\n",
      "        [-5.3402e-02,  1.0842e-01, -7.6622e-03, -1.1098e-01, -5.3672e-02,\n",
      "         -5.4267e-01],\n",
      "        [-5.3166e-02,  1.0843e-01, -3.5330e-02, -2.0750e-01, -5.0842e-02,\n",
      "         -2.2458e-01],\n",
      "        [-5.3508e-02,  1.0841e-01, -3.5326e-02,  7.6818e-03, -4.4782e-02,\n",
      "         -2.5210e-01],\n",
      "        [-5.3728e-02,  9.2392e-01, -3.5334e-02, -3.5483e-01, -5.6410e-02,\n",
      "         -6.2848e-01],\n",
      "        [-5.3377e-02,  1.0842e-01,  1.6996e-01, -3.8195e-01, -5.8963e-02,\n",
      "          1.9603e+00],\n",
      "        [-5.3434e-02,  1.0842e-01, -3.5334e-02, -2.1062e-01, -5.9670e-02,\n",
      "          2.2593e+00],\n",
      "        [-5.3048e-02,  1.0844e-01, -2.0798e-02, -2.7129e-01, -5.0904e-02,\n",
      "          5.6003e-01],\n",
      "        [ 8.4095e-01,  9.8738e-01, -3.5334e-02, -3.0239e-01, -6.3577e-02,\n",
      "         -2.8512e-01],\n",
      "        [ 9.9037e-01,  1.8246e-01, -3.5330e-02,  1.4472e-02, -6.0224e-02,\n",
      "         -6.5162e-01],\n",
      "        [ 9.9449e-01,  9.9827e-01,  7.5591e-02, -1.6642e-01, -6.3854e-02,\n",
      "         -5.6017e-01],\n",
      "        [ 6.4992e-01,  9.7383e-01, -3.5331e-02, -3.8578e-01, -4.8874e-02,\n",
      "         -3.9755e-01],\n",
      "        [ 9.6749e-01,  9.9636e-01,  1.4019e-01, -3.7562e-01, -4.9827e-02,\n",
      "         -6.6743e-01],\n",
      "        [ 9.4988e-01,  9.9511e-01, -3.5334e-02,  7.5399e+00, -3.5431e-02,\n",
      "         -7.0017e-01]])\n",
      "Shape of features: torch.Size([64, 8])\n",
      "Shape of labels: torch.Size([64, 6])\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset('H1_AI_Dataset/Dataset1_Input.csv', 'H1_AI_Dataset/Dataset1_Labels.csv')\n",
    "\n",
    "for features, labels in dataloader:  # This correctly unpacks each batch into features and labels\n",
    "    print(\"Features:\\n\", features)\n",
    "    print(\"Labels:\\n\", labels)\n",
    "    print(\"Shape of features:\", features.shape)  \n",
    "    print(\"Shape of labels:\", labels.shape)  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f488f9-8f84-48fb-9383-cc5073542980",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=8, hidden_size=[256,256,256,256], output_size=6):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size[0])  # BatchNorm for the first hidden layer\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size[1])  # BatchNorm for the second hidden layer\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_size[1], hidden_size[2])\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_size[2])  # BatchNorm for the third hidden layer\n",
    "        \n",
    "        self.fc4 = nn.Linear(hidden_size[2], hidden_size[3])\n",
    "        self.bn4 = nn.BatchNorm1d(hidden_size[3])  # BatchNorm for the fourth hidden layer\n",
    "        \n",
    "        self.fc5 = nn.Linear(hidden_size[3], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)  # Apply BatchNorm after fc1\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)  # Apply BatchNorm after fc2\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)  # Apply BatchNorm after fc3\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.bn4(x)  # Apply BatchNorm after fc4\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        \n",
    "        x = self.fc5(x)  # No BatchNorm before the final layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b32e5d9f-4d0d-41f4-afd8-68398b643533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, optimizer, and loss function\n",
    "model = MLP()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_function = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c097db2a-49ad-428b-b775-59c89f80d2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=8, out_features=256, bias=True)\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (bn4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc5): Linear(in_features=256, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "787b9190-7288-4f40-8220-68a40bd4f831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Training Loss: 0.3223, Test Loss: 0.2957\n",
      "Epoch [2/4], Training Loss: 0.3031, Test Loss: 0.2891\n",
      "Epoch [3/4], Training Loss: 0.3001, Test Loss: 0.2911\n",
      "Epoch [4/4], Training Loss: 0.2976, Test Loss: 0.2879\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training Phase\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_train_loss = 0\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Testing Phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_test_loss = 0\n",
    "    with torch.no_grad():  # Inference mode, gradients not needed\n",
    "        for batch_idx, (data, targets) in enumerate(test_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "    # Print Epoch Summary\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {total_train_loss/len(train_loader):.4f}, Test Loss: {total_test_loss/len(test_loader):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
