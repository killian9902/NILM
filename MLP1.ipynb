{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "483e9e1e-a2c0-4d1a-9564-28c5762779a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f5529-ba04-4840-b1d0-912bae4979cb",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed971555-ed0b-4602-9057-c454b184747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, features_file, label_file):\n",
    "        self.features = pd.read_csv(features_file)\n",
    "        self.labels = pd.read_csv(label_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tensor_features = torch.tensor(self.features.iloc[idx].values, dtype=torch.float)\n",
    "        tensor_labels = torch.tensor(self.labels.iloc[idx].values, dtype=torch.float)\n",
    "\n",
    "        return tensor_features, tensor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292268ac-d0e0-4620-b5e0-60f597eed2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset('H1_AI_Dataset/H1_Features_Wh.csv', 'H1_AI_Dataset/H1_Labels_Wh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9355e1ac-48c9-40c9-bf09-0fa1ad291e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "def87605-7498-422e-8a6b-2398964bc866",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e4c2a-621a-4ae5-9342-673c43a007e6",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "176de7c1-1579-4f81-baab-73f8d9ab4f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=8, hidden_size=128, output_size=6):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.fc5 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        \n",
    "        x = self.fc5(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bf84d83-60f5-4477-8270-1a6cf14a81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, optimizer, and loss function\n",
    "model = MLP()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_function = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd349cc2-6433-44ce-8ee2-bae23d534793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=8, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc5): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61fbe980-b9fa-415b-bc2a-d23e4c77bdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Training Loss: 9.0707\n",
      "Epoch [1/4], Test Loss: 9.2874\n",
      "Epoch [2/4], Training Loss: 9.1995\n",
      "Epoch [2/4], Test Loss: 9.2100\n",
      "Epoch [3/4], Training Loss: 9.1888\n",
      "Epoch [3/4], Test Loss: 9.2330\n",
      "Epoch [4/4], Training Loss: 9.1891\n",
      "Target: [ 3.4838889 39.92472    0.5005556  9.539166   7.4641666  0.       ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 1.9411111   0.74527776  0.5005556  24.169445    3.6752777   2.9983332 ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 0.31555554 47.038612    0.49805555 56.316666    8.005       4.3758335 ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 0.25527778 15.879444    0.5005556   1.0033333   4.8441668   1.1066667 ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 0.2625     16.631111    0.50555557 10.3972225   3.9458334   3.5933332 ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [2.8658333  1.2491666  0.5013889  0.91833335 3.7152777  3.0683334 ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [  0.2502778  49.12583    53.45139   235.50917     8.072778   14.279722 ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 0.25194445  4.814722    0.49944445 15.264444    3.7316666   3.0119445 ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 9.385278    0.7475      0.50027776  5.7727776   3.8041666  16.03139   ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 0.26944444  0.7372222   0.49944445 91.004166    5.2658334   3.7441666 ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [0.25055555 0.7488889  0.49944445 3.7194445  3.7419446  1.8094444 ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [5.325278   0.7380555  0.49888888 1.0041667  3.7413888  0.        ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 5.5825     16.518333    0.74916667  2.468611    4.8436112  14.044167  ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [4.7694445  0.7475     0.49805555 1.0025     5.046111   3.0033333 ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 38.880833     0.74222225  95.03111    242.20944      3.8211112\n",
      "   3.041389  ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 0.76055557  0.74916667  0.7505556   1.0011111   3.7525     10.125556  ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 2.7077777  40.934444    0.49861112  1.0044445   7.333611    0.        ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [0.5172222  0.74472225 0.50083333 0.7475     3.735      3.2544444 ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 8.070278    0.75027776  0.5011111  23.101944    4.876111   15.620556  ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 9.561111  17.139444   0.5005556 24.178888   3.89       3.2447221]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Target: [ 0.33583334  0.74222225 19.870277    4.5844445   4.2988887   3.0725    ]\n",
      "Output: [ 2.0250604   0.755925    0.50089645 11.346676    3.8476155   3.1127763 ]\n",
      "Epoch [4/4], Test Loss: 9.2219\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    \n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, targets) in enumerate(train_dataloader):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {total_loss/len(train_dataloader):.4f}')\n",
    "\n",
    "    \n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_test_loss = 0\n",
    "    with torch.no_grad():  # No need to track gradients for validation data\n",
    "        for batch_idx, (data, targets) in enumerate(test_dataloader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            \n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "\n",
    "            # Randomly print data and targets based on percentage - on last epoch\n",
    "            if (epoch == num_epochs-1) and (random.random() < 0.1):\n",
    "                \n",
    "                # Pick a random item index from the batch\n",
    "                item_idx = random.randint(0, data.size(0) - 1)\n",
    "\n",
    "                # Extract and print the data, target, and output for the randomly selected item\n",
    "                item_target = targets[item_idx]\n",
    "                item_output = outputs[item_idx]\n",
    "                \n",
    "                print(f\"Target: {item_target.cpu().numpy()}\")\n",
    "                print(f\"Output: {item_output.cpu().numpy()}\")\n",
    "\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Test Loss: {total_test_loss/len(test_dataloader):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
